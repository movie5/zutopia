{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2텍스트전처리.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIr/GZJ89jrxIGtpK6/nFo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/movie5/zutopia/blob/master/2%ED%85%8D%EC%8A%A4%ED%8A%B8%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk-B4FUss-UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVCzA7cKeKhB",
        "colab_type": "text"
      },
      "source": [
        "02 텍스트 전처리 \n",
        "\n",
        "    01) 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dGJMCDR22Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRoxDK8x22Ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(word_tokenize(\"What's wrong with you\")) # What 과 's로 분리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGrrIAwG22Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer  #don ' t 따로따로 분리\n",
        "print(WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsJiSnxo3dCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer=TreebankWordTokenizer()\n",
        "text=\"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print(tokenizer.tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsaQCICNtYI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to mae sure no one was near.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGtWm-YjuQQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text=\"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXVIbCQNzSF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install kss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjzqMEZeJqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq7-gGVz0NUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text='딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어려워요. 농담아니에요. 이제 해보면 알걸요?'\n",
        "print(kss.split_sentences(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhRb0d9DvJeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4p9nyyBhCFz",
        "colab_type": "text"
      },
      "source": [
        "1) morphs : 형태소 추출\n",
        "\n",
        "2) pos : 품사 태깅(Part-of-speech tagging)\n",
        "\n",
        "3) nouns : 명사 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7hJuUKfvKth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls sms-tools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIRYceDGvNQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.signal import blackmanharris, triang\n",
        "from scipy.fftpack import ifft\n",
        "import math\n",
        "import dftModel as DFT\n",
        "import utilFunctions as UF\n",
        "import sineModel as SM\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUaeHXRTvYp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
        "shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "print(shortword.sub('', text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mel3-puzWnU",
        "colab_type": "text"
      },
      "source": [
        "##어간 추출(Stemming) and 표제어 추출(Lemmatization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GExmq6ZeiwoM",
        "colab_type": "text"
      },
      "source": [
        "###표제어 추출(Lemmatization)\n",
        "1) 어간(stem)\n",
        ": 단어의 의미를 담고 있는 단어의 핵심 부분.\n",
        "\n",
        "2) 접사(affix)\n",
        ": 단어에 추가적인 의미를 주는 부분."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2KLedz3i-A3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e5250686-d7c5-42d4-82a3-f2ecdf48236f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osoTdNjCi32H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1562a6a7-60a2-4204-9f54-fa03d4ded1ad"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer #dy ha 같이 의미를 알 수 없는 얘들도 뽑힘\n",
        "n=WordNetLemmatizer()\n",
        "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print([n.lemmatize(w) for w in words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkBsXKtXjwYt",
        "colab_type": "text"
      },
      "source": [
        "표제어 추출기(lemmatizer)가 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwRWiELCi4Jn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "018745ae-ad8c-4c4b-ef71-02112ab56458"
      },
      "source": [
        "n.lemmatize('dies', 'v')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'die'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI7KGWoAj0OQ",
        "colab_type": "text"
      },
      "source": [
        "###2. 어간 추출(Stemming)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jisPrEVTj7eO",
        "colab_type": "text"
      },
      "source": [
        "어간 추출 알고리즘 중 하나인 포터 알고리즘(Porter Algorithm)에 아래의 Text를 입력으로 넣는다고 해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhQlxivLjyXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ff3ac575-51f1-4815-d8fe-07395456a173"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "s = PorterStemmer()\n",
        "text=\"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "words=word_tokenize(text)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh-VT7bIkYjO",
        "colab_type": "text"
      },
      "source": [
        "가령, 포터 알고리즘의 어간 추출은 이러한 규칙들을 가집니다.\n",
        "\n",
        "ALIZE → AL\n",
        "\n",
        "ANCE → 제거\n",
        "\n",
        "ICAL → IC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNoJ6tNUj9e5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d71eba5f-e7e0-4f0d-9376-569ef69cdc25"
      },
      "source": [
        "words=['formalize', 'allowance', 'electricical']\n",
        "print([s.stem(w) for w in words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['formal', 'allow', 'electric']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXpbXSgwkgWG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a4e5b798-00a0-4fcf-a307-6281da115c35"
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "l=LancasterStemmer()\n",
        "words=['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print([l.stem(w) for w in words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZQVyMTbmF4F",
        "colab_type": "text"
      },
      "source": [
        "마지막으로, 같은 단어에 대해서 표제어 추출과 어간 추출을 각각 수행했을 때, 결과에서 어떤 차이가 있는지 간단한 예를 보겠습니다.\n",
        "\n",
        "Stemming\n",
        "\n",
        "am → am\n",
        "\n",
        "the going → the go\n",
        "\n",
        "having → hav\n",
        "\n",
        "\n",
        "Lemmatization\n",
        "\n",
        "am → be\n",
        "\n",
        "the going → the going\n",
        "\n",
        "having → have"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDh1RjWWmNya",
        "colab_type": "text"
      },
      "source": [
        "한국어의 특징\n",
        "\n",
        "언\t품사\n",
        "\n",
        "체언\t명사, 대명사, 수사\n",
        "\n",
        "수식언\t관형사, 부사\n",
        "\n",
        "관계언\t조사\n",
        "\n",
        "독립언  \t감탄사\n",
        "\n",
        "용언\t동사, 형용사\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "어간(stem) : 용언(동사, 형용사)을 활용할 때, 원칙적으로 모양이 변하지 않는 부분. 활용에서 어미에 선행하는 부분. 때론 어간의 모양도 바뀔 수 있음(예: 긋다, 긋고, 그어서, 그어라).\n",
        "\n",
        "어미(ending): 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분이며, 여러 문법적 기능을 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmFrZukJmuMP",
        "colab_type": "text"
      },
      "source": [
        "예를 들어 ‘듣-, 돕-, 곱-, 잇-, 오르-, 노랗-’ 등이 ‘듣/들-, 돕/도우-, 곱/고우-, 잇/이-, 올/올-, 노랗/노라-’와 같이 어간의 형식이 달라지는 일이 있거나 ‘오르+ 아/어→올라, 하+아/어→하여, 이르+아/어→이르러, 푸르+아/어→푸르러’와 같이 일반적인 어미가 아닌 특수한 어미를 취하는 경우 불규칙활용을 하는 예에 속합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGlxA4D9m4TH",
        "colab_type": "text"
      },
      "source": [
        "#4) 불용어(stopword)\n",
        "\n",
        "----\n",
        "예를 들면, I, my, me, over, 조사, 접미사 같은 단어들은 문장에서는 자주 등장하지만 실제 의미 분석을 하는데는 거의 기여하는 바가 없는 경우가 있습니다. 이러한 단어들을 불용어(stopword)라고 하며, NLTK에서는 위와 같은 100여개 이상의 영어 단어들을 불용어로 패키지 내에서 미리 정의하고 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "testCtSmnF1s",
        "colab_type": "text"
      },
      "source": [
        "1. NLTK에서 불용어 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5_GmmLYnJ-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "d50acfd2-8cf6-4eb5-8571-e48d2e57ce4b"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HygOWOr7mt5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2dd2780-882b-46f2-a4d7-256987b007d5"
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "stopwords.words('english')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5DuqzZOnYjv",
        "colab_type": "text"
      },
      "source": [
        "2. NLTK를 이용해서 stopword 제거하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqA-1JUrmBPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4f418221-07ec-4ccd-9506-e16a3dff177d"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "example = \"Family is not an important thing. It's everything.\"\n",
        "stop_words = set(stopwords.words('english')) #set 자료구조오오\n",
        "\n",
        "word_tokens = word_tokenize(example)\n",
        "\n",
        "result = []\n",
        "for w in word_tokens:         #for문 파이선에서는 잘 씁니다\n",
        "    if w not in stop_words: \n",
        "        result.append(w) \n",
        "\n",
        "print(word_tokens) \n",
        "print(result) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
            "['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysIrzwzwnsCb",
        "colab_type": "text"
      },
      "source": [
        "3. 한국어에서 불용어 제거하기\n",
        "\n",
        "---\n",
        "조사나 접속사와 같은 단어들뿐만 아니라 명사, 형용사와 같은 단어들 중에서 불용어로서 제거하고 싶은 단어들이 생기기도 합니다. 결국에는 사용자가 직접 불용어 사전을 만들게 되는 경우가 많습니다. \n",
        "\n",
        "---\n",
        "\n",
        "한국어 불용어를 제거하는 더 좋은 방법은 코드 내에서 직접 정의하지 않고 txt 파일이나 csv 파일로 수많은 불용어를 정리해놓고, 이를 불러와서 사용하는 방법입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpaNCq-Ancs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9d5fd075-e379-48dd-b12c-eeddac63ec5e"
      },
      "source": [
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"아무거나 아무렇게나 어찌하든지 같다 비슷하다 예컨대 이럴정도로 하면 아니거든\"\n",
        "# 위의 불용어는 명사가 아닌 단어 중에서 저자가 임의로 선정한 것으로 실제 의미있는 선정 기준이 아님\n",
        "stop_words=stop_words.split(' ')\n",
        "word_tokens = word_tokenize(example)\n",
        "\n",
        "result = [] \n",
        "for w in word_tokens: \n",
        "    if w not in stop_words: \n",
        "        result.append(w) \n",
        "# 위의 4줄은 아래의 한 줄로 대체 가능\n",
        "# result=[word for word in word_tokens if not word in stop_words]\n",
        "\n",
        "print(word_tokens) \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['고기를', '아무렇게나', '구우려고', '하면', '안', '돼', '.', '고기라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n",
            "['고기를', '구우려고', '안', '돼', '.', '고기라고', '다', '같은', '게', '.', '삼겹살을', '구울', '때는', '중요한', '게', '있지', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFahr7C5oHd9",
        "colab_type": "text"
      },
      "source": [
        "#05) 정규 표현식(Regular Expression)\n",
        "---\n",
        "1) .기호\n",
        "\n",
        ".은 한 개의 임의의 문자를 나타냅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAw2aXH6n0sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"a.c\")\n",
        "r.search(\"kkk\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr25sP45o28o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f069339a-fd4f-43f6-beb2-0f4d4befaf1a"
      },
      "source": [
        "r.search(\"abc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3sfvy7zo6Cf",
        "colab_type": "text"
      },
      "source": [
        "2) ?기호\n",
        "\n",
        "\n",
        "?는 ? 앞의 문자가 존재할 수도 있고, 존재하지 않을 수도 있는 경우를 나타냅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbWO4H2wo4ns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"ab?c\")\n",
        "r.search(\"abbc\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPi3hyxipAgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3c9d56c-6fad-4da7-9dc4-0c7314ef607b"
      },
      "source": [
        "r.search(\"abc\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBvJmK9dpCGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abdc54af-4f20-45e4-80f2-d6a40bb2e56d"
      },
      "source": [
        "r.search(\"ac\") #b가 없는 것으로 판단하여 ac를 매치하는 것을 볼 수 있습니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 2), match='ac'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COu3u-4BpMls",
        "colab_type": "text"
      },
      "source": [
        "3) *기호\n",
        "\n",
        "*은 바로 앞의 문자가 0개 이상일 경우를 나타냅니다. 앞의 문자는 존재하지 않을 수도 있으며, 또는 여러 개일 수도 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHMAxoavpHc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"ab*c\")\n",
        "r.search(\"a\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdkxP-cmpOoz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e8f2e18-7a3f-43c1-b1b0-422bb7ee93ba"
      },
      "source": [
        "r.search(\"abbbbc\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 6), match='abbbbc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8zm0xC2pcH0",
        "colab_type": "text"
      },
      "source": [
        "4) +기호\n",
        "\n",
        "+는 *와 유사합니다. 하지만 다른 점은 앞의 문자가 최소 1개 이상이어야 한다는 점입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI2KZO7PpRAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"ab+c\")\n",
        "r.search(\"ac\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLeiVhIlpewJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18ae05a3-22a3-42de-b83c-3a24590a58e3"
      },
      "source": [
        "r.search(\"abbbbc\") "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 6), match='abbbbc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWCcu1VXpif-",
        "colab_type": "text"
      },
      "source": [
        "5) ^기호\n",
        "\n",
        "^는 시작되는 글자를 지정합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcxPuiaHpgV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"^a\")\n",
        "r.search(\"bbc\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cHcSe7cpk8b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97bbf941-eb0d-4841-b536-a7e39e2565ee"
      },
      "source": [
        "r.search(\"ab\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HGKiLaZpydO",
        "colab_type": "text"
      },
      "source": [
        "7) {숫자1, 숫자2} 기호\n",
        "\n",
        "문자에 해당 기호를 붙이면, 해당 문자를 숫자1 이상 숫자2 이하만큼 반복합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mriEDgQOpnXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"ab{2,8}c\")\n",
        "r.search(\"ac\") # 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"ac\") # 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"abc\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pUXj7fyp06V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff9c4e8b-03bf-4740-8c98-dc3a8b0c1ecd"
      },
      "source": [
        "r.search(\"abbc\") #예를 들어서 정규 표현식이 ab{2,8}c라면 a와 c 사이에 b가 존재하면서 b는 2개 이상 8개 이하인 문자열에 대해서 매치합니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 4), match='abbc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p692-CJzp8e7",
        "colab_type": "text"
      },
      "source": [
        "8) {숫자,} 기호\n",
        "\n",
        "문자에 해당 기호를 붙이면 해당 문자를 숫자 이상 만큼 반복합니다. \n",
        "\n",
        "---\n",
        "\n",
        "또한 만약 {0,}을 쓴다면 *와 동일한 의미가 되며, {1,}을 쓴다면 +와 동일한 의미가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myorvrrEp3V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"a{2,}bc\")\n",
        "r.search(\"bc\") # 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"aa\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q06MoCWfqE3t",
        "colab_type": "text"
      },
      "source": [
        "9) [ ] 기호\n",
        "[ ]안에 문자들을 넣으면 그 문자들 중 한 개의 문자와 매치라는 의미를 가집니다. \n",
        "\n",
        "---\n",
        "\n",
        "[a-zA-Z]는 알파벳 전부를 의미하며, [0-9]는 숫자 전부를 의미합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImQy7_Cep_vH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"[abc]\") # [abc]는 [a-c]와 같다.\n",
        "r.search(\"zzz\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98b67oZbqJYg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be7ca78c-83a6-4d65-a130-43ee302eed40"
      },
      "source": [
        "r.search(\"baac\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 1), match='b'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p54-BkWqMh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"[a-z]\") #알파벳 소문자만\n",
        "r.search(\"AAA\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjB0rNJYqTvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7cdd853-0d75-4c09-acdb-bdd7ea7e2d44"
      },
      "source": [
        "r.search(\"aBC\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 1), match='a'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlEsUIj_qYfg",
        "colab_type": "text"
      },
      "source": [
        "10) [^문자] 기호\n",
        "\n",
        "\n",
        "[^문자]는 5)에서 설명한 ^와는 완전히 다른 의미로 쓰입니다. 여기서는 ^ 기호 뒤에 붙은 문자들을 제외한 모든 문자를 매치하는 역할을 합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGCTPL3CqVZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"[^abc]\")\n",
        "r.search(\"a\") # 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"ab\") # 아무런 결과도 출력되지 않는다.\n",
        "r.search(\"b\") # 아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBUSd6mdqb1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66f76de6-cc7c-442c-fe80-5d33d359337f"
      },
      "source": [
        "r.search(\"d\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 1), match='d'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4nagkx6qcg6",
        "colab_type": "text"
      },
      "source": [
        "#3. 정규 표현식 모듈 함수 예제\n",
        "---\n",
        "##(1) re.match() 와 re.search()의 차이\n",
        "---\n",
        "search()가 정규 표현식 전체에 대해서 문자열이 매치하는지를 본다면, \n",
        "\n",
        "match()는 문자열의 첫 부분부터 정규 표현식과 매치하는지를 확인합니다.\n",
        "\n",
        " 문자열 중간에 찾을 패턴이 있다고 하더라도, match 함수는 문자열의 시작에서 패턴이 일치하지 않으면 찾지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pSAAvscqmPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "r=re.compile(\"ab.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwJVSGDyqtTJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c068b3b-2ee6-4dc3-e4df-feab15ce77e3"
      },
      "source": [
        "r.search(\"kkkabc\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(3, 6), match='abc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8TIqGtvqu0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r.match(\"kkkabc\")  #아무런 결과도 출력되지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ZM8cGarGYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "008ea600-cdd5-4cbc-fecb-d41927a62e7a"
      },
      "source": [
        "r.match(\"abckkk\")  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnmYc42XrHdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuXgXWSwrLS7",
        "colab_type": "text"
      },
      "source": [
        "##(2) re.split()\n",
        "\n",
        "split() 함수는 입력된 정규 표현식을 기준으로 문자열들을 분리하여 리스트로 리턴합니다. 자연어 처리에 있어서 가장 많이 사용되는 정규 표현식 함수 중 하나인데, 토큰화에 유용하게 쓰일 수 있기 때문입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_NS-EverNx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4747b513-6df2-4655-faf1-9ea621b57a59"
      },
      "source": [
        "import re\n",
        "text=\"사과 딸기 수박 메론 바나나\"\n",
        "re.split(\" \",text) #공백 기준으로 분리"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2O0dEZsrf_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "29ab9f2a-90fd-42c4-ee0b-6e14d34cc291"
      },
      "source": [
        "import re\n",
        "text=\"\"\"사과\n",
        "딸기\n",
        "수박\n",
        "메론\n",
        "바나나\"\"\"\n",
        "re.split(\"\\n\",text) #줄바꿈으로 분리"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JVG8SXFrniE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d713a388-dd68-4b6e-ded7-00446b39f335"
      },
      "source": [
        "import re\n",
        "text=\"사과+딸기+수박+메론+바나나\"\n",
        "re.split(\"\\+\",text) #'+'로 분리\n",
        "['사과', '딸기', '수박', '메론', '바나나']  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['사과', '딸기', '수박', '메론', '바나나']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLvTiDf4rsBG",
        "colab_type": "text"
      },
      "source": [
        "###(3) re.findall()\n",
        "\n",
        "findall() 함수는 정규 표현식과 매치되는 모든 문자열들을 리스트로 리턴합니다. 단, 매치되는 문자열이 없다면 빈 리스트를 리턴합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ea8-na3ro3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "7aa8d94b-7bb4-4471-88aa-87e589752467"
      },
      "source": [
        "import re\n",
        "text= \"이름 : 김철수\n",
        "전화번호 : 010 - 1234 - 1234 \n",
        "나이 : 30\n",
        "성별 : 남\" \n",
        "re.findall(\"\\d+\",text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-c077d2ed810f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    text=\"이름 : 김철수\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d76Au6a0sJea",
        "colab_type": "text"
      },
      "source": [
        "###(4) re.sub()\n",
        "\n",
        "sub() 함수는 정규 표현식 패턴과 일치하는 문자열을 찾아 다른 문자열로 대체할 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFfg5OwmryVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1e7277f0-babc-40dc-aed6-a3a4dd398da2"
      },
      "source": [
        "import re\n",
        "text=\"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
        "re.sub('[^a-zA-Z]',' ',text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9acnfcZsTtv",
        "colab_type": "text"
      },
      "source": [
        "## 5. 정규 표현식 텍스트 전처리 예제\n",
        "---\n",
        "'\\s+'는 공백을 찾아내는 정규표현식입니다.\n",
        "뒤에 붙는 +는 최소 1개 이상의 패턴을 찾아낸다는 의미입니다. \n",
        "\n",
        "s는 공백을 의미하기 때문에 최소 1개 이상의 공백인 패턴을 찾아냅니다. \n",
        "\n",
        "입력으로 테이블 형식의 데이터를 텍스트에 저장하였습니다. 각 데이터가 공백으로 구분되어있습니다.\n",
        "\n",
        " split은 주어진 정규표현식을 기준으로 분리하므로 결과는 아래와 같습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d1LuQGtsOhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0906da1-9eee-47e1-daa5-4ce35d1d5628"
      },
      "source": [
        "import re  \n",
        "\n",
        "text = \"\"\"100 John    PROF\n",
        "101 James   STUD\n",
        "102 Mac   STUD\"\"\"  \n",
        "\n",
        "re.split('\\s+', text)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rarp9MzFshXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66349407-027f-48c7-d62e-e80a56e771ba"
      },
      "source": [
        "re.findall('\\d+',text)  #\\d = 숫자만, + = 최소 1개 이상의 숫자에 해당"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', '101', '102']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdlAbAJWsotA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42bf9a55-e9c7-4dac-cf92-7fb57dd5c4b0"
      },
      "source": [
        "re.findall('[A-Z]',text)  #대문자만"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY79Bi9ksrnh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54c38d70-b38e-493f-a104-d270b18050ff"
      },
      "source": [
        "re.findall('[A-Z]{4}',text)  #대문자가 연속으로 4번 등장하는 경우"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROF', 'STUD', 'STUD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zTQPCSSsvuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbdd104c-d136-4eb6-de8f-6fee46d89fb0"
      },
      "source": [
        "re.findall('[A-Z][a-z]+',text) #처음 대문자가 등장하고 그 후에 소문자가 여러번 등장하는 경우 매치"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John', 'James', 'Mac']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGFD5GMKs2p5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "letters_only = re.sub('[^a-zA-Z]', ' ', text) #영문자가 아니면 전부 공백으로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV6CrFg9trE5",
        "colab_type": "text"
      },
      "source": [
        "###6. 정규 표현식을 이용한 토큰화\n",
        "---\n",
        "tokenizer=RegexpTokenizer(\"[\\w]+\")에서 \\+는 문자 또는 숫자가 1개 이상인 경우를 인식하는 코드입니다. 그렇기 때문에 이 코드는 문장에서 구두점을 제외하고, 단어들만을 가지고 토큰화를 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaMSguPWtmAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e976b331-0445-439c-b4e0-5ea9e4b00050"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer=RegexpTokenizer(\"[\\w]+\")\n",
        "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-ixh4a2tybs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "35cd9674-94d3-474a-d47c-4de8dd501e53"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer=RegexpTokenizer(\"[\\s]+\", gaps=True) #공백을 기준으로 토큰화, gaps=True : 정규 표현식을 토큰으로 나누기 위한 기준\n",
        "print(tokenizer.tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3JnwB0luM0a",
        "colab_type": "text"
      },
      "source": [
        "#06) 정수 인코딩(Integer Encoding)\n",
        "\n",
        "----\n",
        "\n",
        "각 단어를 고유한 정수에 맵핑(mapping)시키는 전처리 작업이 필요할 때가 있습니다.\n",
        "---\n",
        "###1. 정수 인코딩(Integer Encoding)\n",
        "---\n",
        "단어에 정수를 부여하는 방법 중 하나로 단어를 빈도수 순으로 정렬한 단어 집합(vocabulary)을 만들고, 빈도수가 높은 순서대로 차례로 낮은 숫자부터 정수를 부여하는 방법이 있습니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAv5jGu6ukq1",
        "colab_type": "text"
      },
      "source": [
        "1) dictionary 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdZoa00bt8bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4BzC0saumUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chS_dMXbunv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2be44289-a2d7-4a46-ce89-4676f5631fba"
      },
      "source": [
        "# 문장 토큰화\n",
        "text = sent_tokenize(text)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A barber is a person.', 'a barber is good person.', 'a barber is huge person.', 'he Knew A Secret!', 'The Secret He Kept is huge secret.', 'Huge secret.', 'His barber kept his word.', 'a barber kept his word.', 'His barber kept his secret.', 'But keeping and keeping such a huge secret to himself was driving the barber crazy.', 'the barber went up a huge mountain.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X82KbBzupY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "31f88dbc-c0b3-4a20-bb23-34bb5ca6231f"
      },
      "source": [
        "# 정제와 단어 토큰화\n",
        "vocab = {} # 파이썬의 dictionary 자료형\n",
        "sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for i in text:\n",
        "    sentence = word_tokenize(i) # 단어 토큰화를 수행합니다.\n",
        "    result = []\n",
        "\n",
        "    for word in sentence: \n",
        "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄입니다. \n",
        "        #위의 코드를 보면, 동일한 단어가 대문자로 표기되었다는 이유로 \n",
        "        #서로 다른 단어로 카운트되는 일이 없도록 모든 단어를 소문자로 바꾸었습니다. \n",
        "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어(의미없는단어)를 제거합니다.\n",
        "            if len(word) > 2: # 단어 길이가 2이하인 경우(의미없는단어)에 대하여 추가로 단어를 제거합니다.\n",
        "                result.append(word)\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = 0 \n",
        "                vocab[word] += 1\n",
        "    sentences.append(result) \n",
        "print(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHJ5pIlGusjS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "37375bdb-9e05-47d7-93ac-97b19e954711"
      },
      "source": [
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 8, 'person': 3, 'good': 1, 'huge': 5, 'knew': 1, 'secret': 6, 'kept': 4, 'word': 2, 'keeping': 2, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL3NLHZ2vL8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f53769e2-b303-4cac-dd7d-9a28f679d55e"
      },
      "source": [
        "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse = True)\n",
        "print(vocab_sorted) #(내림차순 정렬)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3), ('word', 2), ('keeping', 2), ('good', 1), ('knew', 1), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Ne_gVPvR_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de59bfe3-02d0-4bb9-842d-58403d7b3b4a"
      },
      "source": [
        "#높은 빈도수 (1등을 주겠다는 말)인 단어일 수록 낮은 정수 인덱스\n",
        "word_to_index = {}\n",
        "i=0\n",
        "for (word, frequency) in vocab_sorted :\n",
        "    if frequency > 1 : # 정제(Cleaning) 챕터에서 언급했듯이 빈도수가 적은 단어는 제외한다.\n",
        "        i=i+1\n",
        "        word_to_index[word] = i\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh5_AcJQvb0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12814a82-4b9e-44ff-c44d-68f921571f0b"
      },
      "source": [
        "vocab_size = 5\n",
        "words_frequency = [w for w,c in word_to_index.items() if c >= vocab_size + 1] # 인덱스가 5 초과인 단어 제거\n",
        "for w in words_frequency:\n",
        "    del word_to_index[w] # 해당 단어에 대한 인덱스 정보를 삭제\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHdi_tIrvxZ8",
        "colab_type": "text"
      },
      "source": [
        "이처럼 단어 집합에 존재하지 않는 단어들을 Out-Of-Vocabulary(단어 집합에 없는 단어)의 약자로 'OOV'라고 합니다. word_to_index에 'OOV'란 단어를 새롭게 추가하고, 단어 집합에 없는 단어들은 'OOV'의 인덱스로 인코딩하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLxnthxHvyS2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_index['OOV'] = len(word_to_index) + 1 #맨 끝번호 줄게"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFQI5M8sv4zP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6d708170-48e5-41e0-e501-e15750eeb2b3"
      },
      "source": [
        "encoded = []\n",
        "for s in sentences:\n",
        "    temp = []\n",
        "    for w in s:\n",
        "        try:\n",
        "            temp.append(word_to_index[w])\n",
        "        except KeyError:\n",
        "            temp.append(word_to_index['OOV'])\n",
        "    encoded.append(temp)\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 6, 5], [1, 3, 5], [6, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [6, 6, 3, 2, 6, 1, 6], [1, 6, 3, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BclyLKr5v7Os",
        "colab_type": "text"
      },
      "source": [
        "여기까지 열심히 코드를 쳣지만 비효율적임 ㅇㅇ\n",
        "케라스 토크나이저 쓰자 그냥 어차피 많아서 못 외울거 유명한거나 쓰자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UdKKg8TwIIP",
        "colab_type": "text"
      },
      "source": [
        "## 2) Counter 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp1zbT17v5KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcu7rgnmwMGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "51a17255-67ac-4760-9de1-7353900965b1"
      },
      "source": [
        "print(sentences)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y4XY0NqwNyu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "de2f66e6-68a7-4342-b6e3-f862c61e7c13"
      },
      "source": [
        "words = sum(sentences, [])\n",
        "# 위 작업은 words = np.hstack(sentences)로도 수행 가능.\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['barber', 'person', 'barber', 'good', 'person', 'barber', 'huge', 'person', 'knew', 'secret', 'secret', 'kept', 'huge', 'secret', 'huge', 'secret', 'barber', 'kept', 'word', 'barber', 'kept', 'word', 'barber', 'kept', 'secret', 'keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy', 'barber', 'went', 'huge', 'mountain']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu7xadbxwRST",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b84099da-4a18-4776-dd0b-3ce959102268"
      },
      "source": [
        "vocab = Counter(words) # 파이썬의 Counter 모듈을 이용하면 중복을 제거하고 단어의 모든 빈도를 쉽게 계산할 수 있습니다.\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, 'crazy': 1, 'went': 1, 'mountain': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRIey0hywVqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9911eab-7f2f-4c6d-f6d7-55bac6523d84"
      },
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahyayOkhwXqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "667f97ea-8905-44fc-ddc4-7e22f9dcce70"
      },
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-xmaXN_wdOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e0c6d14-7c60-4958-ba9e-3369369868b5"
      },
      "source": [
        "word_to_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in vocab :\n",
        "    i = i+1\n",
        "    word_to_index[word] = i #높은 빈도수 일수록 낮은 인덱스\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8vu69-zwoW-",
        "colab_type": "text"
      },
      "source": [
        "3) NLTK의 FreqDist 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKv_knQQwnWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk import FreqDist\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i2ucmDQwrPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# np.hstack으로 문장 구분을 제거하여 입력으로 사용 . ex) ['barber', 'person', 'barber', 'good' ... 중략 ...\n",
        "vocab = FreqDist(np.hstack(sentences))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-x7jA7rwsqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70b78e29-ecd4-4300-c362-96a7e703c24e"
      },
      "source": [
        "print(vocab[\"barber\"]) # 'barber'라는 단어의 빈도수 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5LNhHiKwuLF",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ri_bKA4vwxFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "705ac415-cb02-43df-fe31-e6b690f87100"
      },
      "source": [
        "vocab_size = 5\n",
        "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
        "vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj5a1bn_w0e3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7973c66-a52e-4c5a-f07e-423bcf6cc827"
      },
      "source": [
        "word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)} #enumerate\n",
        "print(word_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S_DWxkRw72-",
        "colab_type": "text"
      },
      "source": [
        "##4) enumerate 이해하기 \n",
        "---\n",
        "enumerate()는 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력으로 받아 인덱스를 순차적으로 함께 리턴한다는 특징이 있습니다. 간단한 예제를 통해 enumerate()를 이해해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjtF9-6aw4v2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9150dca9-9ad9-4d3d-99d7-c9e2e3e2be84"
      },
      "source": [
        "test=['a', 'b', 'c', 'd', 'e']\n",
        "for index, value in enumerate(test): # 입력의 순서대로 0부터 인덱스를 부여함.\n",
        "  print(\"value : {}, index: {}\".format(value, index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "value : a, index: 0\n",
            "value : b, index: 1\n",
            "value : c, index: 2\n",
            "value : d, index: 3\n",
            "value : e, index: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THjq-676xI66",
        "colab_type": "text"
      },
      "source": [
        "#2. 케라스(Keras)의 텍스트 전처리\n",
        "---\n",
        "그냥 이거 씁시다. 케라스잖아요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yoAxtwnxDaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LteIH3iBxP3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences=[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXgYotEpxROF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences) # fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성한다.\n",
        "#fit_on_texts는 입력한 텍스트로부터 단어 빈도수가 높은 순으로 낮은 정수 인덱스를 부여하는데, 정확히 앞서 설명한 정수 인코딩 작업이 이루어진다고"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbnlJwKKxWb6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5766483c-750d-4bf8-9ea3-d6d4627a1c6c"
      },
      "source": [
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5, 'word': 6, 'keeping': 7, 'good': 8, 'knew': 9, 'driving': 10, 'crazy': 11, 'went': 12, 'mountain': 13}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57XgS685xXxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "41bc0d02-a6ac-4d93-a5ef-c86d20fa8125"
      },
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('barber', 8), ('person', 3), ('good', 1), ('huge', 5), ('knew', 1), ('secret', 6), ('kept', 4), ('word', 2), ('keeping', 2), ('driving', 1), ('crazy', 1), ('went', 1), ('mountain', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCGOKQkExZlL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "03fe4029-07aa-4fad-eae3-6887d1fedaa5"
      },
      "source": [
        "print(tokenizer.texts_to_sequences(sentences))\n",
        "#texts_to_sequences()는 입력으로 들어온 코퍼스에 대해서 각 단어를 이미 정해진 인덱스로 변환합니다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJDzDfvSxciQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 1) # 상위 5개 단어만 사용\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMNgk8SCxjdI",
        "colab_type": "text"
      },
      "source": [
        "num_words에서 +1을 더해서 값을 넣어주는 이유는 num_words는 숫자를 0부터 카운트합니다. 만약 5를 넣으면 0 ~ 4번 단어 보존을 의미하게 되므로 뒤의 실습에서 1번 단어부터 4번 단어만 남게됩니다. 그렇기 때문에 1 ~ 5번 단어까지 사용하고 싶다면 num_words에 숫자 5를 넣어주는 것이 아니라 5+1인 값을 넣어주어야 합니다.\n",
        "\n",
        "실질적으로 숫자 0에 지정된 단어가 존재하지 않는데도 케라스 토크나이저가 숫자 0까지 단어 집합의 크기로 산정하는 이유는 자연어 처리에서 패딩(padding)이라는 작업 때문입니다. 이에 대해서는 뒤에 다루게 되므로 여기서는 케라스 토크나이저를 사용할 때는 숫자 0도 단어 집합의 크기로 고려해야한다고만 이해합시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWg9z1vXxew_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e7707016-a150-4efc-ba14-facf5e0943cd"
      },
      "source": [
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 5], [1, 3, 5], [2], [2, 4, 3, 2], [3, 2], [1, 4], [1, 4], [1, 4, 2], [3, 2, 1], [1, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oxFW3tTxtUm",
        "colab_type": "text"
      },
      "source": [
        "케라스 토크나이저는 기본적으로 단어 집합에 없는 단어인 OOV에 대해서는 단어를 정수로 바꾸는 과정에서 아예 단어를 제거한다는 특징이 있습니다. 단어 집합에 없는 단어들은 OOV로 간주하여 보존하고 싶다면 Tokenizer의 인자 oov_token을 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL3gPm8ixoRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 5\n",
        "tokenizer = Tokenizer(num_words = vocab_size + 2, oov_token = 'OOV')\n",
        "# 빈도수 상위 5개 단어만 사용. 숫자 0과 OOV를 고려해서 단어 집합의 크기는 +2\n",
        "tokenizer.fit_on_texts(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyk48lmNxvmz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4037c0b7-cd8f-482f-c99f-6502e24bd8c8"
      },
      "source": [
        "print('단어 OOV의 인덱스 : {}'.format(tokenizer.word_index['OOV']))\n",
        "#일반적으로 1을 부여함"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 OOV의 인덱스 : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5e7U8I0x4Gz",
        "colab_type": "text"
      },
      "source": [
        "#07) 패딩(Padding)\n",
        "---\n",
        "병렬 연산을 위해서 여러 문장의 길이를 임의로 동일하게 맞춰주는 작업\n",
        "\n",
        " 이와 같이 데이터에 특정 값을 채워서 데이터의 크기(shape)를 조정하는 것을 패딩(padding)이라고 합니다. \n",
        " \n",
        "  *숫자 0을 사용하고 있다면 **제로 패딩(zero padding)**이라고 합니다.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re01rMeDy0b5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjR4S89KyBuG",
        "colab_type": "text"
      },
      "source": [
        "1. Numpy로 패딩하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ByoH6Nx24S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7p6xNcpex0TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIqVF1FtyFVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#정수인코딩\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences) # fit_on_texts()안에 코퍼스를 입력으로 하면 빈도수를 기준으로 단어 집합을 생성한다.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihEYxmukyK53",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ec0cf6a-e824-4631-b5e1-223ffcb2f862"
      },
      "source": [
        "encoded = tokenizer.texts_to_sequences(sentences)\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig5mQuMryMU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67e71aa0-3a70-4f09-b005-ef371e459685"
      },
      "source": [
        "#동일한 길이로 맞춰주기 위해 가장 길이가 긴 문장의 길이를 계산\n",
        "max_len = max(len(item) for item in encoded)\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKklEGA_yRdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "b6250962-81e8-4df2-874c-26338536a764"
      },
      "source": [
        "for item in encoded: # 각 문장에 대해서\n",
        "    while len(item) < max_len:   # max_len보다 작으면\n",
        "        item.append(0)\n",
        "\n",
        "padded_np = np.array(encoded)\n",
        "padded_np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0,  0,  0],\n",
              "       [ 3,  2,  0,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMgxjjq7y15n",
        "colab_type": "text"
      },
      "source": [
        "##08) 원-핫 인코딩(One-Hot Encoding)\n",
        "---\n",
        "**단어 집합(vocabulary)**\n",
        "\n",
        "\n",
        ":텍스트의 모든 단어를 중복을 허용하지 않고 모아놓으면 이를 단어 집합이라고 합니다.\n",
        "\n",
        "\n",
        "단어 집합(vocabulary)에서는 기본적으로 book과 books와 같이 단어의 변형 형태도 다른 단어로 간주합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMpVG0q0zF-i",
        "colab_type": "text"
      },
      "source": [
        "##1. 원-핫 인코딩(One-Hot Encoding)이란?\n",
        "---\n",
        "(1) 각 단어에 고유한 인덱스를 부여합니다. \n",
        "\n",
        "(정수 인코딩)\n",
        "\n",
        "(2) 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KQBNQYryU8A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "0e98ef15-e321-4833-cfef-dcbd4b44baed"
      },
      "source": [
        "!pip install konlpy\n",
        "from konlpy.tag import Okt  \n",
        "okt=Okt()  \n",
        "token=okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
        "print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 55.0MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/9b/e115101a833605b3c0e6f3a2bc1f285c95aaa1d93ab808314ca1bde63eed/JPype1-0.7.5-cp36-cp36m-manylinux2010_x86_64.whl (3.6MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6MB 41.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.1MB/s \n",
            "\u001b[?25hCollecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, beautifulsoup4, tweepy, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "Successfully installed JPype1-0.7.5 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n",
            "['나', '는', '자연어', '처리', '를', '배운다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9VZBrDYzRNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c62dcbed-4a1c-4459-c12a-e9c1fe1b7ba5"
      },
      "source": [
        "#고유 인덱스 부여\n",
        "word2index={}\n",
        "for voca in token:\n",
        "     if voca not in word2index.keys():\n",
        "       word2index[voca]=len(word2index)\n",
        "print(word2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9ARNZfJzk-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c84d7a67-af2f-4a12-cbe4-89fc87bd3c72"
      },
      "source": [
        "def one_hot_encoding(word, word2index): # 원-핫 벡터를 만들어내는 함수\n",
        "       one_hot_vector = [0]*(len(word2index))\n",
        "       index=word2index[word]\n",
        "       one_hot_vector[index]=1\n",
        "       return one_hot_vector\n",
        "\n",
        "\n",
        "one_hot_encoding(\"자연어\",word2index) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbz3kfFVzzOl",
        "colab_type": "text"
      },
      "source": [
        "케라스에서도 지원하네요 역시 케라스 짱"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BleMEFDhzpqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=\"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91j4GbPIz3Ko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28ea3b93-573f-4b86-94d7-2d7dac42716f"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text=\"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\"\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts([text])\n",
        "print(t.word_index) # 각 단어에 대한 인코딩 결과 출력."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEP2AH38z5T9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4345bcc-2d07-4018-e527-b4e80f92b068"
      },
      "source": [
        "sub_text=\"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
        "encoded=t.texts_to_sequences([sub_text])[0]\n",
        "print(encoded)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 5, 1, 6, 3, 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBFElxsTz7vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "eaa21f3e-5567-44ef-de0b-01fb5714ffaa"
      },
      "source": [
        "one_hot = to_categorical(encoded) #정수 인코딩 된 결과에서 원-핫 인코딩을 수행하는 함수\n",
        "print(one_hot)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfKGyGRe0A72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE0P80Ws0Csg",
        "colab_type": "text"
      },
      "source": [
        "원-핫 인코딩(One-Hot Encoding)의 한계\n",
        "\n",
        "---\n",
        "가령, 단어가 1,000개인 코퍼스를 가지고 원 핫 벡터를 만들면, 모든 단어 각각은 모두 1,000개의 차원을 가진 벡터가 됩니다. \n",
        "\n",
        "\n",
        "원-핫 벡터는 단어의 유사도를 표현하지 못한다는 단점\n",
        "\n",
        "\n",
        "----\n",
        "이러한 단점을 해결하기 위해 단어의 잠재 의미를 반영하여 다차원 공간에 벡터화 하는 기법으로 크게 두 가지가 있습니다. \n",
        "\n",
        "1. 첫째는 카운트 기반의 벡터화 방법인 LSA, HAL 등이 있으며,\n",
        "\n",
        "2. 둘째는 예측 기반으로 벡터화하는 NNLM, RNNLM, Word2Vec, FastText 등이 있습니다. 그리고 카운트 기반과 예측 기반 두 가지 방법을 모두 사용하는 방법으로 GloVe라는 방법이 존재합니다.\n",
        "\n",
        "이 책에서는 이 중에서 6챕터에서 LSA를 다룰 예정이며, 10챕터에서는 Word2Vec, FastText, GloVe를 다룹니다."
      ]
    }
  ]
}